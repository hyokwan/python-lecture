{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae9063a2-553d-434b-a64a-074354b9a943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 7578511306475470201\n",
       " xla_global_id: -1]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7ea607a-bfaa-492b-8146-3ee6d2caff3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9700\\744918632.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# GPU 사용 가능 -> True, GPU 사용 불가 -> False\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# GPU 사용 가능 -> True, GPU 사용 불가 -> False\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2eb169-98a7-44ec-96e0-ae8db38b1801",
   "metadata": {},
   "source": [
    "### 1. 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d74dd32-926a-42f5-b06b-8a4bf1c322c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 127] 지정된 프로시저를 찾을 수 없습니다. Error loading \"C:\\Users\\kopo\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolov8n.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\ultralytics\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ultralytics YOLO 🚀, AGPL-3.0 license\u001b[39;00m\n\u001b[0;32m      3\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m8.0.180\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RTDETR, SAM, YOLO\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfastsam\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastSAM\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NAS\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\ultralytics\\models\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ultralytics YOLO 🚀, AGPL-3.0 license\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrtdetr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RTDETR\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msam\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SAM\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01myolo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\ultralytics\\models\\rtdetr\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ultralytics YOLO 🚀, AGPL-3.0 license\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RTDETR\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpredict\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RTDETRPredictor\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RTDETRValidator\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\ultralytics\\models\\rtdetr\\model.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ultralytics YOLO 🚀, AGPL-3.0 license\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mRT-DETR model interface\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RTDETRDetectionModel\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpredict\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RTDETRPredictor\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\ultralytics\\engine\\model.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Union\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcfg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TASK2DATA, get_cfg, get_save_dir\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HUB_WEB_ROOT\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m attempt_load_one_weight, guess_model_task, nn, yaml_model_load\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\ultralytics\\cfg\\__init__.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleNamespace\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict, List, Union\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (ASSETS, DEFAULT_CFG, DEFAULT_CFG_DICT, DEFAULT_CFG_PATH, LOGGER, RANK, SETTINGS,\n\u001b[0;32m     12\u001b[0m                                SETTINGS_YAML, IterableSimpleNamespace, __version__, checks, colorstr, deprecation_warn,\n\u001b[0;32m     13\u001b[0m                                yaml_load, yaml_print)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Define valid tasks and modes\u001b[39;00m\n\u001b[0;32m     16\u001b[0m MODES \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexport\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrack\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbenchmark\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\ultralytics\\utils\\__init__.py:21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myaml\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm \u001b[38;5;28;01mas\u001b[39;00m tqdm_original\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\__init__.py:129\u001b[0m\n\u001b[0;32m    127\u001b[0m     err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(last_error)\n\u001b[0;32m    128\u001b[0m     err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    131\u001b[0m     is_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 127] 지정된 프로시저를 찾을 수 없습니다. Error loading \"C:\\Users\\kopo\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ec52c8-a3dc-45d7-a07d-857b14a82b63",
   "metadata": {},
   "source": [
    "### 2. 재학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f689c7b-04bf-4ea7-a69f-c9d2494c5f0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c2214e3-52a4-4cd3-a212-42c1d7c6305c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imgPath = \"./images/plates/data.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13b510aa-61ba-4f30-9d4e-d01d583e2ee9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.208 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.180  Python-3.11.5 torch-2.1.0+cpu CPU (Intel Core(TM) i7-7500U 2.70GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=./images/plates/data.yaml, epochs=20, patience=30, batch=32, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=0, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train17\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    757747  ultralytics.nn.modules.head.Detect           [33, [64, 128, 256]]          \n",
      "Model summary: 225 layers, 3017283 parameters, 3017267 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\kopo\\devcode\\Session97 - Yolo\\images\\plates\\train\\labels.cache... 126 images, 0 backgrounds\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\kopo\\devcode\\Session97 - Yolo\\images\\plates\\valid\\labels.cache... 12 images, 0 backgrounds, 0\u001b[0m\n",
      "Plotting labels to runs\\detect\\train17\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00027, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train17\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/20         0G      3.875      4.894      3.144        483        640: 100%|██████████| 4/4 [01:28<00:00, 22\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:0\n",
      "                   all         12         92          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/20         0G      3.915      4.857      3.181        379        640: 100%|██████████| 4/4 [01:31<00:00, 22\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:0\n",
      "                   all         12         92          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/20         0G      3.834      4.871      3.055        486        640: 100%|██████████| 4/4 [01:34<00:00, 23\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:0\n",
      "                   all         12         92          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/20         0G      3.724      4.782      2.972        424        640: 100%|██████████| 4/4 [01:30<00:00, 22\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:0\n",
      "                   all         12         92          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/20         0G      3.599      4.808      2.901        367        640: 100%|██████████| 4/4 [01:29<00:00, 22\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:0\n",
      "                   all         12         92          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/20         0G      3.501      4.753      2.779        443        640: 100%|██████████| 4/4 [01:26<00:00, 21\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:0\n",
      "                   all         12         92          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/20         0G      3.402      4.677      2.709        446        640: 100%|██████████| 4/4 [01:31<00:00, 22\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:0\n",
      "                   all         12         92          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/20         0G      3.132      4.663      2.543        406        640: 100%|██████████| 4/4 [01:35<00:00, 23\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:0\n",
      "                   all         12         92          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/20         0G      2.993      4.587      2.423        436        640: 100%|██████████| 4/4 [01:29<00:00, 22\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:0\n",
      "                   all         12         92          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/20         0G      2.814      4.518      2.369        472        640: 100%|██████████| 4/4 [01:33<00:00, 23\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:0\n",
      "                   all         12         92    0.00198     0.0143    0.00152   0.000606\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/20         0G      3.119      4.403      2.511        223        640: 100%|██████████| 4/4 [01:26<00:00, 21\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:0\n",
      "                   all         12         92    0.00347      0.056    0.00689    0.00174\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/20         0G      2.935      4.359      2.413        222        640: 100%|██████████| 4/4 [01:25<00:00, 21\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:0\n",
      "                   all         12         92    0.00556       0.17     0.0161    0.00659\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/20         0G      2.671      4.257      2.153        225        640: 100%|██████████| 4/4 [01:17<00:00, 19\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:0\n",
      "                   all         12         92     0.0134      0.273      0.028     0.0145\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/20         0G      2.536      4.216      2.102        227        640: 100%|██████████| 4/4 [01:24<00:00, 21\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:0\n",
      "                   all         12         92    0.00955      0.287     0.0354     0.0185\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/20         0G      2.591      4.144       2.14        225        640: 100%|██████████| 4/4 [01:27<00:00, 21\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:0\n",
      "                   all         12         92    0.00777        0.3     0.0411     0.0207\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/20         0G      2.457      4.141      2.024        225        640: 100%|██████████| 4/4 [01:17<00:00, 19\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:0\n",
      "                   all         12         92    0.00769      0.309     0.0413     0.0197\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/20         0G      2.389      4.109      1.994        222        640: 100%|██████████| 4/4 [01:16<00:00, 19\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:0\n",
      "                   all         12         92    0.00835      0.323     0.0475      0.024\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      18/20         0G      2.296      4.043      1.926        233        640: 100%|██████████| 4/4 [01:17<00:00, 19\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:0\n",
      "                   all         12         92     0.0082      0.328     0.0448     0.0227\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      19/20         0G      2.345      4.075      1.945        227        640: 100%|██████████| 4/4 [01:23<00:00, 20\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:0\n",
      "                   all         12         92     0.0082      0.328     0.0373     0.0192\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      20/20         0G      2.315      4.025      1.906        229        640: 100%|██████████| 4/4 [01:23<00:00, 20\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:0\n",
      "                   all         12         92     0.0085      0.335     0.0422     0.0223\n",
      "\n",
      "20 epochs completed in 0.505 hours.\n",
      "Optimizer stripped from runs\\detect\\train17\\weights\\last.pt, 6.3MB\n",
      "Optimizer stripped from runs\\detect\\train17\\weights\\best.pt, 6.3MB\n",
      "\n",
      "Validating runs\\detect\\train17\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.180  Python-3.11.5 torch-2.1.0+cpu CPU (Intel Core(TM) i7-7500U 2.70GHz)\n",
      "Model summary (fused): 168 layers, 3012083 parameters, 0 gradients, 8.1 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:0\n",
      "                   all         12         92    0.00838      0.323     0.0473     0.0237\n",
      "                     0         12          8      0.025       0.75     0.0746     0.0441\n",
      "                     1         12          2    0.00274        0.5     0.0213    0.00786\n",
      "                     2         12          7     0.0239      0.714     0.0447     0.0164\n",
      "                     3         12          3          0          0          0          0\n",
      "                     4         12          9          0          0          0          0\n",
      "                     5         12          7     0.0167      0.143    0.00965    0.00386\n",
      "                     6         12          5          0          0          0          0\n",
      "                     7         12          2    0.00676          1      0.261      0.176\n",
      "                     8         12          4     0.0185       0.25     0.0275    0.00275\n",
      "                     9         12          2          0          0          0          0\n",
      "                     A         12          2    0.00617        0.5    0.00956    0.00287\n",
      "                     B         12          1          0          0          0          0\n",
      "                     C         12          6     0.0187      0.333     0.0158    0.00693\n",
      "                     D         12          5     0.0157        0.6      0.024     0.0138\n",
      "                     E         12          2     0.0082        0.5    0.00878    0.00263\n",
      "                     F         12          3          0          0          0          0\n",
      "                     G         12          4     0.0278       0.25     0.0228     0.0114\n",
      "                     J         12          2          0          0          0          0\n",
      "                     M         12          1      0.008          1     0.0711     0.0168\n",
      "                     N         12          3          0          0          0          0\n",
      "                     P         12          3     0.0186          1      0.467      0.201\n",
      "                     R         12          1          0          0          0          0\n",
      "                     S         12          2     0.0323          1      0.256      0.153\n",
      "                     T         12          2    0.00568        0.5     0.0101     0.0036\n",
      "                     V         12          1          0          0          0          0\n",
      "                     W         12          1          0          0          0          0\n",
      "                     X         12          2          0          0          0          0\n",
      "                     Z         12          2          0          0          0          0\n",
      "Speed: 4.1ms preprocess, 218.4ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train17\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "fittedModel = model.train(data=imgPath,\n",
    "             epochs=20,\n",
    "             patience=30,\n",
    "             batch=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cdc42f0e-cf3d-461d-8aa2-a0aa2fcd11c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\kopo\\devcode\\Session97 - Yolo\\images\\plates\\train\\images\\13803638414728_png.rf.600db7c7c20157cf518a2abe2f24cdb4.jpg: 640x640 (no detections), 402.7ms\n",
      "Speed: 9.6ms preprocess, 402.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: 'A', 11: 'B', 12: 'C', 13: 'D', 14: 'E', 15: 'F', 16: 'G', 17: 'H', 18: 'I', 19: 'J', 20: 'K', 21: 'L', 22: 'M', 23: 'N', 24: 'P', 25: 'R', 26: 'S', 27: 'T', 28: 'V', 29: 'W', 30: 'X', 31: 'Y', 32: 'Z'}\n",
       " orig_img: array([[[214, 214, 214],\n",
       "         [201, 201, 201],\n",
       "         [152, 152, 152],\n",
       "         ...,\n",
       "         [156, 157, 155],\n",
       "         [229, 230, 228],\n",
       "         [255, 255, 254]],\n",
       " \n",
       "        [[214, 214, 214],\n",
       "         [201, 201, 201],\n",
       "         [152, 152, 152],\n",
       "         ...,\n",
       "         [156, 157, 155],\n",
       "         [229, 230, 228],\n",
       "         [255, 255, 254]],\n",
       " \n",
       "        [[214, 214, 214],\n",
       "         [201, 201, 201],\n",
       "         [152, 152, 152],\n",
       "         ...,\n",
       "         [156, 157, 155],\n",
       "         [229, 230, 228],\n",
       "         [255, 255, 254]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[201, 201, 201],\n",
       "         [193, 193, 193],\n",
       "         [149, 149, 149],\n",
       "         ...,\n",
       "         [155, 155, 155],\n",
       "         [227, 227, 227],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[201, 201, 201],\n",
       "         [193, 193, 193],\n",
       "         [149, 149, 149],\n",
       "         ...,\n",
       "         [155, 155, 155],\n",
       "         [227, 227, 227],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[201, 201, 201],\n",
       "         [193, 193, 193],\n",
       "         [149, 149, 149],\n",
       "         ...,\n",
       "         [155, 155, 155],\n",
       "         [227, 227, 227],\n",
       "         [255, 255, 255]]], dtype=uint8)\n",
       " orig_shape: (416, 416)\n",
       " path: 'C:\\\\Users\\\\kopo\\\\devcode\\\\Session97 - Yolo\\\\images\\\\plates\\\\train\\\\images\\\\13803638414728_png.rf.600db7c7c20157cf518a2abe2f24cdb4.jpg'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict'\n",
       " speed: {'preprocess': 9.613275527954102, 'inference': 402.71639823913574, 'postprocess': 1.9960403442382812}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testPath = \"./images/plates/train//images/13803638414728_png.rf.600db7c7c20157cf518a2abe2f24cdb4.jpg\"\n",
    "model.predict(source=testPath, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfb7478-27f3-4b92-8b86-da631a7b4dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70d3ce88-e907-43f7-bf36-c140e323559f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testSource = \"./images/plates/train//images/13803638414728_png.rf.600db7c7c20157cf518a2abe2f24cdb4.jpg\"\n",
    "img = cv2.imread(testSource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "316bbc27-a4f3-49d6-86a4-f8e0710e1bab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 317.5ms\n",
      "Speed: 6.2ms preprocess, 317.5ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "results = model(img)\n",
    "res_plotted = results[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b56d69-fcdd-4526-95c5-e5aae81a932d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2224a1-48cf-49b4-8483-328b0338b041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b9f034-ba5c-45ee-994d-6662f65e93c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2dab8a-a712-414f-9139-acca934154a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd4703a9-5dc7-42cd-b064-f798c6fabfae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22594dce-725b-4e1c-91bc-8ae24be6f37a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\kopo\\devcode\\Session97 - Yolo\\images\\plates\\valid\\images\\mpuma_jpg.rf.8aec128d012011e06f3957c126ea0d84.jpg: 640x640 (no detections), 303.2ms\n",
      "Speed: 14.0ms preprocess, 303.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "results = model(testSource)\n",
    "res_plotted = results[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35bb58ae-cec5-4d18-806c-b30c45d37fe8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "imshow() missing 1 required positional argument: 'mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow( res_plotted[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] )\n",
      "\u001b[1;31mTypeError\u001b[0m: imshow() missing 1 required positional argument: 'mat'"
     ]
    }
   ],
   "source": [
    "cv2.imshow( res_plotted[0][0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d278e11-a336-4580-a877-82ed588ec8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bbox outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    probs = result.probs  # Class probabilities for classification outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08d09c51-c685-4bfa-b730-fa4bd36c58be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\kopo\\devcode\\Session97 - Yolo\\images\\plates\\valid\\images\\mpuma_jpg.rf.8aec128d012011e06f3957c126ea0d84.jpg: 640x640 (no detections), 316.1ms\n",
      "Speed: 6.1ms preprocess, 316.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: 'A', 11: 'B', 12: 'C', 13: 'D', 14: 'E', 15: 'F', 16: 'G', 17: 'H', 18: 'I', 19: 'J', 20: 'K', 21: 'L', 22: 'M', 23: 'N', 24: 'P', 25: 'R', 26: 'S', 27: 'T', 28: 'V', 29: 'W', 30: 'X', 31: 'Y', 32: 'Z'}\n",
       " orig_img: array([[[ 74, 114, 163],\n",
       "         [ 79, 119, 167],\n",
       "         [ 73, 115, 162],\n",
       "         ...,\n",
       "         [101, 139, 181],\n",
       "         [111, 148, 192],\n",
       "         [114, 151, 195]],\n",
       " \n",
       "        [[ 64, 104, 153],\n",
       "         [ 85, 125, 173],\n",
       "         [ 63, 105, 152],\n",
       "         ...,\n",
       "         [ 88, 126, 168],\n",
       "         [110, 147, 191],\n",
       "         [122, 159, 203]],\n",
       " \n",
       "        [[ 68, 108, 157],\n",
       "         [ 99, 139, 187],\n",
       "         [ 62, 104, 151],\n",
       "         ...,\n",
       "         [ 69, 107, 149],\n",
       "         [106, 145, 189],\n",
       "         [128, 167, 211]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 66, 106, 141],\n",
       "         [ 24,  64,  99],\n",
       "         [ 37,  75, 109],\n",
       "         ...,\n",
       "         [100, 142, 187],\n",
       "         [ 80, 122, 167],\n",
       "         [ 75, 117, 162]],\n",
       " \n",
       "        [[ 69, 109, 144],\n",
       "         [ 24,  64,  99],\n",
       "         [ 27,  65, 100],\n",
       "         ...,\n",
       "         [ 92, 135, 178],\n",
       "         [ 87, 129, 172],\n",
       "         [ 79, 121, 164]],\n",
       " \n",
       "        [[ 73, 113, 148],\n",
       "         [ 27,  67, 102],\n",
       "         [ 20,  58,  93],\n",
       "         ...,\n",
       "         [ 90, 133, 176],\n",
       "         [ 93, 135, 178],\n",
       "         [ 80, 122, 165]]], dtype=uint8)\n",
       " orig_shape: (416, 416)\n",
       " path: 'C:\\\\Users\\\\kopo\\\\devcode\\\\Session97 - Yolo\\\\images\\\\plates\\\\valid\\\\images\\\\mpuma_jpg.rf.8aec128d012011e06f3957c126ea0d84.jpg'\n",
       " probs: None\n",
       " save_dir: None\n",
       " speed: {'preprocess': 6.129980087280273, 'inference': 316.06173515319824, 'postprocess': 1.995086669921875}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1232a93a-70db-4abb-89b1-40f808881b1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = YOLO(\"./runs/detect/train17/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a13c4ed-e62a-4662-9e23-7cb002dfa686",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sourcePath = \"./videos/car_plates1.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "259c3486-428e-4266-80eb-3594d82f8560",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 (no detections), 105.5ms\n",
      "Speed: 3.6ms preprocess, 105.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 131.4ms\n",
      "Speed: 3.4ms preprocess, 131.4ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 116.6ms\n",
      "Speed: 3.0ms preprocess, 116.6ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 88.4ms\n",
      "Speed: 3.9ms preprocess, 88.4ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 104.4ms\n",
      "Speed: 3.0ms preprocess, 104.4ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 110.3ms\n",
      "Speed: 3.4ms preprocess, 110.3ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 111.6ms\n",
      "Speed: 2.7ms preprocess, 111.6ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 101.2ms\n",
      "Speed: 3.2ms preprocess, 101.2ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 94.5ms\n",
      "Speed: 2.8ms preprocess, 94.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 106.5ms\n",
      "Speed: 3.0ms preprocess, 106.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 116.4ms\n",
      "Speed: 2.8ms preprocess, 116.4ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 102.2ms\n",
      "Speed: 2.6ms preprocess, 102.2ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 99.8ms\n",
      "Speed: 2.5ms preprocess, 99.8ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 112.5ms\n",
      "Speed: 3.0ms preprocess, 112.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 113.8ms\n",
      "Speed: 2.8ms preprocess, 113.8ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 90.4ms\n",
      "Speed: 4.2ms preprocess, 90.4ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 111.0ms\n",
      "Speed: 2.7ms preprocess, 111.0ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 93.6ms\n",
      "Speed: 2.6ms preprocess, 93.6ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 108.8ms\n",
      "Speed: 3.4ms preprocess, 108.8ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 140.9ms\n",
      "Speed: 4.6ms preprocess, 140.9ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 121.9ms\n",
      "Speed: 3.6ms preprocess, 121.9ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 104.2ms\n",
      "Speed: 3.6ms preprocess, 104.2ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 123.4ms\n",
      "Speed: 3.4ms preprocess, 123.4ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 110.4ms\n",
      "Speed: 2.5ms preprocess, 110.4ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 99.2ms\n",
      "Speed: 3.3ms preprocess, 99.2ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 113.4ms\n",
      "Speed: 3.5ms preprocess, 113.4ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 94.1ms\n",
      "Speed: 3.0ms preprocess, 94.1ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 96.7ms\n",
      "Speed: 3.0ms preprocess, 96.7ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 104.8ms\n",
      "Speed: 3.0ms preprocess, 104.8ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 108.6ms\n",
      "Speed: 2.9ms preprocess, 108.6ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 123.9ms\n",
      "Speed: 2.7ms preprocess, 123.9ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 94.4ms\n",
      "Speed: 3.3ms preprocess, 94.4ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 111.8ms\n",
      "Speed: 2.5ms preprocess, 111.8ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 99.8ms\n",
      "Speed: 2.5ms preprocess, 99.8ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 110.0ms\n",
      "Speed: 3.0ms preprocess, 110.0ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 98.5ms\n",
      "Speed: 3.0ms preprocess, 98.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 129.1ms\n",
      "Speed: 3.5ms preprocess, 129.1ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 103.5ms\n",
      "Speed: 3.0ms preprocess, 103.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 111.6ms\n",
      "Speed: 4.1ms preprocess, 111.6ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 104.2ms\n",
      "Speed: 3.0ms preprocess, 104.2ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 110.7ms\n",
      "Speed: 3.8ms preprocess, 110.7ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 95.5ms\n",
      "Speed: 4.0ms preprocess, 95.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 112.8ms\n",
      "Speed: 4.0ms preprocess, 112.8ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 107.6ms\n",
      "Speed: 3.0ms preprocess, 107.6ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 111.9ms\n",
      "Speed: 2.9ms preprocess, 111.9ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 100.8ms\n",
      "Speed: 4.0ms preprocess, 100.8ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 98.0ms\n",
      "Speed: 3.0ms preprocess, 98.0ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 117.1ms\n",
      "Speed: 3.0ms preprocess, 117.1ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 100.0ms\n",
      "Speed: 3.0ms preprocess, 100.0ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 116.0ms\n",
      "Speed: 2.6ms preprocess, 116.0ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 108.0ms\n",
      "Speed: 5.1ms preprocess, 108.0ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 96.5ms\n",
      "Speed: 3.1ms preprocess, 96.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 98.3ms\n",
      "Speed: 3.0ms preprocess, 98.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 96.5ms\n",
      "Speed: 2.7ms preprocess, 96.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 91.5ms\n",
      "Speed: 2.6ms preprocess, 91.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 104.6ms\n",
      "Speed: 3.0ms preprocess, 104.6ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 109.1ms\n",
      "Speed: 9.8ms preprocess, 109.1ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 101.7ms\n",
      "Speed: 2.8ms preprocess, 101.7ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 97.1ms\n",
      "Speed: 4.0ms preprocess, 97.1ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 97.2ms\n",
      "Speed: 2.7ms preprocess, 97.2ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 109.3ms\n",
      "Speed: 4.0ms preprocess, 109.3ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 106.7ms\n",
      "Speed: 4.0ms preprocess, 106.7ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 122.4ms\n",
      "Speed: 3.0ms preprocess, 122.4ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 108.1ms\n",
      "Speed: 3.5ms preprocess, 108.1ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 109.8ms\n",
      "Speed: 4.0ms preprocess, 109.8ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 98.3ms\n",
      "Speed: 3.0ms preprocess, 98.3ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 93.7ms\n",
      "Speed: 3.0ms preprocess, 93.7ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 90.1ms\n",
      "Speed: 3.0ms preprocess, 90.1ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 92.8ms\n",
      "Speed: 2.9ms preprocess, 92.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 92.3ms\n",
      "Speed: 3.0ms preprocess, 92.3ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 103.4ms\n",
      "Speed: 3.1ms preprocess, 103.4ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 107.5ms\n",
      "Speed: 4.6ms preprocess, 107.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 112.8ms\n",
      "Speed: 3.0ms preprocess, 112.8ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 99.3ms\n",
      "Speed: 3.0ms preprocess, 99.3ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 108.3ms\n",
      "Speed: 5.1ms preprocess, 108.3ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 108.2ms\n",
      "Speed: 3.0ms preprocess, 108.2ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 99.8ms\n",
      "Speed: 2.7ms preprocess, 99.8ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 102.6ms\n",
      "Speed: 3.9ms preprocess, 102.6ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 103.4ms\n",
      "Speed: 4.6ms preprocess, 103.4ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 114.5ms\n",
      "Speed: 3.2ms preprocess, 114.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 93.5ms\n",
      "Speed: 3.0ms preprocess, 93.5ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 97.8ms\n",
      "Speed: 4.0ms preprocess, 97.8ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 118.6ms\n",
      "Speed: 2.9ms preprocess, 118.6ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 87.4ms\n",
      "Speed: 3.0ms preprocess, 87.4ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 93.2ms\n",
      "Speed: 3.0ms preprocess, 93.2ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 91.4ms\n",
      "Speed: 3.0ms preprocess, 91.4ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 89.3ms\n",
      "Speed: 2.9ms preprocess, 89.3ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 105.2ms\n",
      "Speed: 3.0ms preprocess, 105.2ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 98.0ms\n",
      "Speed: 2.2ms preprocess, 98.0ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 95.3ms\n",
      "Speed: 2.8ms preprocess, 95.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 130.0ms\n",
      "Speed: 5.0ms preprocess, 130.0ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 156.0ms\n",
      "Speed: 1.7ms preprocess, 156.0ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 160.0ms\n",
      "Speed: 3.0ms preprocess, 160.0ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 110.1ms\n",
      "Speed: 3.0ms preprocess, 110.1ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 126.9ms\n",
      "Speed: 3.0ms preprocess, 126.9ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 103.9ms\n",
      "Speed: 3.0ms preprocess, 103.9ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 109.7ms\n",
      "Speed: 2.9ms preprocess, 109.7ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 108.9ms\n",
      "Speed: 3.0ms preprocess, 108.9ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 92.2ms\n",
      "Speed: 3.0ms preprocess, 92.2ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 107.7ms\n",
      "Speed: 3.0ms preprocess, 107.7ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 98.9ms\n",
      "Speed: 3.2ms preprocess, 98.9ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 121.2ms\n",
      "Speed: 3.0ms preprocess, 121.2ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 100.6ms\n",
      "Speed: 2.0ms preprocess, 100.6ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 114.4ms\n",
      "Speed: 3.0ms preprocess, 114.4ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 94.4ms\n",
      "Speed: 3.0ms preprocess, 94.4ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 154.5ms\n",
      "Speed: 4.0ms preprocess, 154.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 117.5ms\n",
      "Speed: 3.4ms preprocess, 117.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 107.6ms\n",
      "Speed: 4.0ms preprocess, 107.6ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 (no detections), 104.9ms\n",
      "Speed: 2.9ms preprocess, 104.9ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n"
     ]
    }
   ],
   "source": [
    "# 캠 0,1 중 두번째 선택\n",
    "capture = cv2.VideoCapture(sourcePath)\n",
    "# capture = cv2.VideoCapture(0)\n",
    "\n",
    "while (capture.isOpened):\n",
    "    ret, frame = capture.read()\n",
    "\n",
    "    if ret:\n",
    "        results = model(frame)\n",
    "        \n",
    "        predFrame = results[0].plot()\n",
    "        cv2.imshow(\"YOLOV8\", predFrame)\n",
    "        \n",
    "        key = cv2.waitKey(33)#1) & 0xFF\n",
    "        # esc 종료\n",
    "        if key == 27:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cc2a35-50ce-4eb8-9d14-dc0c77f174e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
